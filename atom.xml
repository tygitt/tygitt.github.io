<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ty-blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-10T12:55:38.754Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>tygitt</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hadoop-hdfs</title>
    <link href="http://yoursite.com/2019/07/10/hadoop-hdfs/"/>
    <id>http://yoursite.com/2019/07/10/hadoop-hdfs/</id>
    <published>2019-07-10T12:54:49.000Z</published>
    <updated>2019-07-10T12:55:38.754Z</updated>
    
    <content type="html"><![CDATA[<h4 id="HDFS-hadoop分布式文件系统"><a href="#HDFS-hadoop分布式文件系统" class="headerlink" title="HDFS-hadoop分布式文件系统"></a>HDFS-hadoop分布式文件系统</h4><p>hdfs(hadoop distributed file system)分布式文件存储系统，hdfs的集群搭建，可以搭建单节点类型，也可以搭建高可用hdfs集群。</p><p>hdfs集群采用的是master/slave（主人/奴隶）架构。NameNode是主节点 DataNode是从节点</p><p>hdfs集群适合一次存储，多次读取的情形，不适合频繁的修改。因为会产生大量的元数据信息</p><p>hdfs采用分块存储，2.x版本 每个block块的大小为128M</p><p>在单节点的hdfs集群中，主要有这么几个角色：</p><ol><li>NameNode：hdfs集群中的主节点，主要负责存储元数据信息（元数据：描述数据的数据，例如名称、时间、大小、路径等信息），以及接收用户的上传下载请求。</li><li>SecondaryNameNode：辅助节点，主要负责NameNode进行元数据信息的管理，负责fsimages与edits 文件的合并。</li><li>DataNode：数据节点，主要负责具体文件的存储，提供存储功能。</li></ol><p>在高可用的hdsf集群之中，会存在两个NameNode。一个是active状态，另一个是standby状态，当第一台NameNode宕机之后，standby状态的NameNode会切换为active状态的NameNode，确保集群的高可用。  高可用状态下的hdfs集群，会有负责进行两个NameNode 信息同步的模块JournalNode，负责两个NameNode之间的信息同步，确保所有的DataNode看到的元数据信息是一致的。高可用hdfs集群，不会有secondaryNameNode的存在，被JournalNode取代。</p><p>NameNode的状态切换主要是通过两个守护进行zkfc来实现。</p><p>常用的hdfs操作命令，与linux的操作类似：</p><ul><li><p>查看指定目录下的所有的文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls /(path)</span><br></pre></td></tr></table></figure></li><li><p>创建文件夹， -p表示创建parent文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir -p /path/path/..</span><br></pre></td></tr></table></figure></li><li><p>文件的剪切，少用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mv dir</span><br></pre></td></tr></table></figure></li><li><p>文件的复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cp file</span><br></pre></td></tr></table></figure></li><li><p>文件的删除 ，-r表示递归的删除该路径下的所有，删除后会被收集到垃圾箱（如果配置了的话）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rm -r /path</span><br></pre></td></tr></table></figure></li><li><p>文件的上传，把文件上传到指定的hdfs目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put file /path</span><br></pre></td></tr></table></figure></li><li><p>文件的下载，从hdfs下载到local</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -get hdfsfilr localdir</span><br></pre></td></tr></table></figure></li><li><p>文件的权限管理，-R表示递归的为此目录下所有的文件都修改权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -chmod -R 777 /path</span><br></pre></td></tr></table></figure><p>改变文件的所属用户和所属组</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -chowm -R  hadoop:hadoop /path</span><br></pre></td></tr></table></figure></li></ul><p>高级命令的使用：主要是可以对文件的大小 数量进行限制</p><ul><li><p>设置指定目录的文件上传目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -setQuota 2 list</span><br></pre></td></tr></table></figure><p>表示list这个文件夹只可以有两个文件，但是文件夹本身也会有一个文件信息，所以用户只能上传一个文件</p></li><li><p>清除文件的数量上传限制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -clrQuota /path</span><br></pre></td></tr></table></figure><p>表示清除掉，该路径下的文件上传数量限制</p></li><li><p>对文件的上传大小进行限制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -setSpaceQuota 4k /path</span><br></pre></td></tr></table></figure><p>表示对指定路径下的文件，进行文件大小的限制</p></li><li><p>清除文件上传的大小限制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -clrSpaceQuota /path</span><br></pre></td></tr></table></figure><p>清除掉指定path的文件夹的文件大小上传限制</p></li></ul><p><strong>在hadoop集群搭建好之后，第一件事就是要对hdfs进行，压力的基准测试，测试hdfs集群的读写速度，和网络带宽是否足够。</strong></p><p><strong>通常hdfs集群的写入速度大约在30MB/s，读取速度大约在100MB/s</strong></p><h4 id="hdfs中的元数据管理"><a href="#hdfs中的元数据管理" class="headerlink" title="hdfs中的元数据管理"></a>hdfs中的元数据管理</h4><p>hdfs的配置信息主要在hdfs-site.xml中进行配置，</p><p>元数据的管理主要由NameNode进行管理，SecondaryNameNode进行辅助管理</p><p>首先NameNode中会有一个fsimages的文件</p><p><strong>fsimages保存着一份最为完整的元数据信息，它存在与NameNode的磁盘和内存之中，会随着元数据信息的增多而变大。</strong></p><p><strong>edies保存着最近一段时间的元数据信息的日志，主要由SecondaryNameNode进行管理</strong></p><p><strong>SecondaryNameNode：主要负责fsimages与edits文件的合并，并清空edits，合并的时机有两个条件，一个edits的大小，另一个是edits存在的时间 ，默认的大小为64M，默认的时间为1h，达到任一条件就会触发fsimages与edits文件和合并。</strong></p><h4 id="hdfs中文件的上传流程"><a href="#hdfs中文件的上传流程" class="headerlink" title="hdfs中文件的上传流程"></a>hdfs中文件的上传流程</h4><ol><li>client发出上传文件的请求，请求NameNode进行文件的上传</li><li>NameNode进行该client是否有权限进行文件的上传操作，并给予回应</li><li>收到可以进行文件上传的回复，client会请求NameNode，文件block块上传的目的地。</li><li>NameNode根据副本个数的配置（默认1个block块会由3个DataNode进行存储），返回3台DataNode的地址给客户端</li><li>客户端找到DataNode建立pipeline管道连接，进行文件的上传，文件的上传以packet包（默认64K）的方式上传到DataNode中</li><li>DataNode接受完第一个block会给Client一个ack确认机制，client进行下一个block的上传</li></ol><h4 id="hdfs中文件的下载流程"><a href="#hdfs中文件的下载流程" class="headerlink" title="hdfs中文件的下载流程"></a>hdfs中文件的下载流程</h4><ol><li>client发出文件的下载请求，请求NameNode进行文件的下载</li><li>NameNode判断client的权限，并给予回复，返回文件的部分或全部的block列表</li><li>client会找到最近的DataNode进行文件的下载，（如果客户端本身就是DataNode，就会从本机进行数据的获取，短路读取特性）</li><li>底层是建立Socket Stream 进行文件的读取</li><li>当读取完NameNode返回的block列表之后，文件还没下载完成，会继续请求NameNode接下来的block所在的DataNode</li><li>每读取完成一个block，都会进行checksum的验证，如果下载出现错误，client会从另一个DataNode进行下载，原来下载的数据，会被丢弃掉，从头开始下载。</li><li>最终读取到所有的block,合并成一个完整的文件</li></ol><p><strong>值得注意的是,文件的上传和下载,数据流不会经过NameNode,NameNode只会返回相应的响应,给出DataNode的地址。</strong></p><h4 id="hdfs的javaAPI操作"><a href="#hdfs的javaAPI操作" class="headerlink" title="hdfs的javaAPI操作"></a>hdfs的javaAPI操作</h4><p>使用javaAPI，进行hdfs的操作。</p><p>使用url进行数据的访问：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">demo1</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">    <span class="comment">// 1.注册hfds的url地址，让java能够识别hdfs的url</span></span><br><span class="line">    URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">    </span><br><span class="line">    String url = <span class="string">"hdfs://node01:8020/test/input/test.log"</span>;</span><br><span class="line">    <span class="comment">// 2.打开文件的输入流</span></span><br><span class="line">    InputStream input = <span class="keyword">new</span> URL(url).openStream();</span><br><span class="line">    <span class="comment">// 3.打开输出流 下载到本地的路径</span></span><br><span class="line">    FileOutPutStream output = <span class="keyword">new</span> FileOutPutStream(<span class="function">New <span class="title">File</span><span class="params">(String path)</span>)</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 4.使用commons工具列中的copy方法 进行输入输出流的对接</span></span><br><span class="line">    IOUtils.copy(input,output);</span><br><span class="line">    <span class="comment">// 5.关闭流 使用commons的IOUtils类进行关闭流</span></span><br><span class="line">    IOUtils.closeQuietly(input);</span><br><span class="line">    IOUtils.closeQuietly(output);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 执行完毕，就会把hdfs集群中的指定url下的文件，下载到本地的路径</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>使用文件系统的方式进行hdfs上数据的访问</strong></p><ol><li><p>获得FileSystem对象，有四种方式来进行 FIleSystem对象的获取，获得FileSystem回想，剩下的就好说。</p><p><strong>获得FileSystem对象的四种方法</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 修改Configuration的默认FileSystem</span></span><br><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">configuration.set(<span class="string">"fs.defaultFS"</span>,<span class="string">"hdfs://node01:8020"</span>);</span><br><span class="line">FileSystem fileSystem = FileSystem.get(configuration);</span><br><span class="line"><span class="comment">// 使用FileSystem的静态方法，传入Configuration获得FileSystem对象</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用FileSystem的静态方法传入 URI 和Configuration 在URI中指定路径</span></span><br><span class="line">URI uri = <span class="keyword">new</span> URI(<span class="string">"hdfs://node01:8020"</span>);</span><br><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">FileSystem fileSystem = FileSystem.get(uri,configuration);</span><br><span class="line"><span class="comment">//传入两个参数进行对象的获取</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用FileSystem的静态方法，newInstance()方法，传入Configuration 进行对象的获取</span></span><br><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">configuration.set(<span class="string">"fs.defaultFS"</span>,<span class="string">"hdfs://node01:8020"</span>);</span><br><span class="line"><span class="comment">// 修改Configuration的默认文件系统，为hdfs文件系统</span></span><br><span class="line">FileSystem fileSystem = FileSystem.newInstance(configuration);</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用FileSystem的，newInstance()方法进行对象的获取</span></span><br><span class="line">URI uri = <span class="keyword">new</span> URI(<span class="string">"hdfs://node01:8020"</span>);</span><br><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">FileSystem fileSystem = FileSystem.newInstance(uri,configuration);</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;HDFS-hadoop分布式文件系统&quot;&gt;&lt;a href=&quot;#HDFS-hadoop分布式文件系统&quot; class=&quot;headerlink&quot; title=&quot;HDFS-hadoop分布式文件系统&quot;&gt;&lt;/a&gt;HDFS-hadoop分布式文件系统&lt;/h4&gt;&lt;p&gt;hdfs(h
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>zookeeper总结与hadoop的安装</title>
    <link href="http://yoursite.com/2019/07/01/zookeeper%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2019/07/01/zookeeper总结/</id>
    <published>2019-07-01T13:14:55.000Z</published>
    <updated>2019-07-10T12:05:28.751Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Zookeeper的理解"><a href="#Zookeeper的理解" class="headerlink" title="Zookeeper的理解"></a>Zookeeper的理解</h3><p>​    zookeeper是apache的一个项目，是一个小型的文件协调服务。官方推荐文件存储大小不超过1MB,本质上也是一个小型的文件存储系统。</p><p>​    zookeeper在集群中的配置，通常是奇数台，原因是zookeeper集群之间存在投票选举机制。就是zookeeper集群之间，会选举出一个老大(leader),剩下的都是小弟(follower),另外还有观察者(observer)的角色，不过这个不常用。</p><p><strong>leader：zk集群中的主节点，主要是处理客户端的事务性请求（增删改）create delete set 操作。</strong></p><p><strong>follower：zk集群中的从节点，主要用来处理客户端的非事务型请求（查询），以及转发来自客户端的事务性请求。</strong></p><p>observer：观察者角色，用来处理非事务性请求（查询），转发事务性的请求。该类型节点不参与投票选举机制。</p><p>​    zookeeper在集群中的配置主要有两个地方，一个是zookeeper/conf/zoo.cfg  。 zk的默认配置文件</p><p>修改dataDir的路径.另一个要修改的就是在这个dataDir路径之中添加一个myid文件,标记该zookeeper的id.</p><h4 id="zookeeper中的主从机制与主备机制"><a href="#zookeeper中的主从机制与主备机制" class="headerlink" title="zookeeper中的主从机制与主备机制"></a>zookeeper中的主从机制与主备机制</h4><p>​    zookeeper中的主从机制：zookeeper集群中会存在一个主节点leader，剩余的都是从节点.leader节点进行任务的分配,从节点执行分配的任务.</p><p>​    zookeeper中的主备机制：zookeeper中的主备机制主要针对于集群中的主节点，备用节点主要是为了保证zk集群的24小时高可用，当leader节点宕机之后，备用节点就会转换为leader节点。确保了zk集群的高可用。</p><p><strong>zookeeper集群的基本特性：全局数据的一致性。保证每一台机器的zk中的数据都是一样的。</strong></p><h4 id="zookeeper的shell操作，以及javaAPI的操作"><a href="#zookeeper的shell操作，以及javaAPI的操作" class="headerlink" title="zookeeper的shell操作，以及javaAPI的操作"></a>zookeeper的shell操作，以及javaAPI的操作</h4><p>​    zookeeper中的每一个节点被称为znode，znode既具有文件的特性，也具有文件夹的特性，即该节点下还可以创建子节点。</p><h5 id="常用的zookeeper-shell操作："><a href="#常用的zookeeper-shell操作：" class="headerlink" title="常用的zookeeper shell操作："></a>常用的zookeeper shell操作：</h5><p>​    ls path：查看该路径下所有的znode（节点）</p><p>​    create [-s] [-e] path  [value] ：在指定路径下创建一个节点。</p><p>​                -s 表示创建一个序列化的节点  -e 表示创建一个临时节点，在client断开连接后，该节点会消失</p><p>​    set：修改覆盖节点中的内容</p><p>​    get：获得节点中的内容</p><p>​    delete：删除该节点，如果该节点下有子节点则无法删除</p><p>​    rmr：递归删除，删除该节点和该节点下的所有节点</p><p>​    get path  watch  ： 为该节点添加watch监听，监听该节点的操作。watch只会触发一次。</p><p>​    history：列出命令的历史</p><h5 id="znode节点的属性"><a href="#znode节点的属性" class="headerlink" title="znode节点的属性"></a>znode节点的属性</h5><p>​    通过get命令可以获得该节点的内容和属性。</p><p>​    znode的属性：</p><p>​        dataVersion:数据的版本号，每次对节点进行set操作，该数字会加1，避免了数据更新的顺序问题</p><p>​        cversion:子节点的版本号，子节点有变化就会加1</p><p>​        aclVersion:ACL的版本号</p><p>​        ephemeralOwner:如果该节点是临时节点，则改值表示与该节点绑定的session id 如果不是临时节点，该值为0</p><p>在client与zkServer通信之前，需要建立连接，该链接成为session</p><h5 id="zookeeper的watch机制"><a href="#zookeeper的watch机制" class="headerlink" title="zookeeper的watch机制"></a>zookeeper的watch机制</h5><p>​    zookeeper提供了 <strong>分布式数据发布/订阅</strong> 功能，一个典型的发布/订阅模型。能让多个订阅者同时监听一个发布者，当该发布者的自身状态改变时，会通知所有订阅者。</p><p>​    zookeeper中通过 <strong>watch机制实现这种分布式的通知功能</strong></p><p>​    大致上来说一个监听器Watcher的流程为：<strong>客户端向服务端注册watcher、服务端发生相应事件触发watcher、客户端回调watcher的触发事件的情况</strong></p><p>​    <strong>watch机制是一次性触发的</strong>，即触发之后，就会销毁。</p><p>​    zookeeper使用WatchedEvent对象封装服务端的事件进行传递</p><p>​    WatchedEvent包含三个基本属性：keeperState 通知状态、EventType 事件类型、Path 节点的路径</p><p>​    watcher的事件通知从服务器端发送到客户端是异步的</p><h5 id="zookeeper的javaAPI"><a href="#zookeeper的javaAPI" class="headerlink" title="zookeeper的javaAPI"></a>zookeeper的javaAPI</h5><p>​    这里采用org.apache.curator该框架进行操作。需要导入curator-framework  curator-recipes两个依赖。</p><p>​    javaAPI开发的大致流程：</p><ol><li><p>获得curatorFramework client对象，这里采用curatorFrameworkFactory工厂对象的静态方法，生成curatorFramework 对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(String StrConnection,RetryPolicy retryPolicy);</span><br></pre></td></tr></table></figure><p>第一个参数，代表要连接的zookeeper服务器地址，第二个参数RetryPolicy表示重试策略是一个接口</p><p>这里使用的该接口的一个实现类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RetryPolicy retryPolicy = <span class="keyword">new</span> ExponentiaBackoffRetry(<span class="number">1000</span>,<span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>其中第一参数为，连接失败重连的时间间隔，第二个参数为尝试重连的次数。</p></li><li><p>开启client连接</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.start();</span><br></pre></td></tr></table></figure></li><li><p>执行相应操作</p><p><strong>增加操作：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.create().createParentsIfNeeded().withMode(CreateMode.PERSISTENT).forPath(String path  [,<span class="keyword">byte</span>[] value]);</span><br></pre></td></tr></table></figure><p>其中create()表示创建一个节点</p><p>createParentsIfNeeded()表示如果该节点的路径不存在，创建该路径</p><p>withMode(CreateMode)，传入一个CreateMode枚举类型，表示创建什么类型的节点，有四种类型：永久节点、临时节点、永久序列化节点、临时序列化节点。</p><p>forPath()，表示在哪个路径下创建节点，后面有一个可选参数byte[]，表示该节点的数据</p><p><strong>删除操作：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.delete().forPath(String path);</span><br></pre></td></tr></table></figure><p>删除指定path的节点</p><p><strong>查看操作：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.get().forPath(String path);</span><br></pre></td></tr></table></figure><p>返回一个byte[] 数组。 获得该路径下节点的数据</p></li><li><p>关闭客户端</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.close();</span><br></pre></td></tr></table></figure><p>释放连接</p></li></ol><p><strong>节点的watch机制</strong></p><ol><li><p>通过curatorFrameworkFactory的静态方法获得一个client</p></li><li><p>client.start();  建立连接</p></li><li><p>添加监听器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">TreeCache treeCache = <span class="keyword">new</span> TreeCache(CuratorFramework client,String path);</span><br><span class="line"><span class="comment">//添加节点的treeCache</span></span><br><span class="line">treeCache.getListenable().addListener(<span class="keyword">new</span> TreeCacheListener()&#123;</span><br><span class="line">    <span class="comment">// 使用new 接口的方法，采用匿名内部类创建一个对象</span></span><br><span class="line">    <span class="comment">// 重写该接口中的childEvent()方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">childEvent</span><span class="params">(CuratorFramework client, TreeCacheEvent event)</span> Throws Exception</span>&#123;</span><br><span class="line">        ChildData data = event.getData(); <span class="comment">// 获得监听到的数据</span></span><br><span class="line">        <span class="comment">//.... 相应的逻辑代码</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">treeCache.start(); <span class="comment">// 开始监听</span></span><br><span class="line">Thread.sleep(<span class="number">4000000</span>); <span class="comment">//让这个线程处于休眠状态，一致保持监听状态</span></span><br></pre></td></tr></table></figure><p>值得注意的是，使用javaAPI 添加watcher，该watcher可以被重复的触发，并不是触发一次就销毁</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Zookeeper的理解&quot;&gt;&lt;a href=&quot;#Zookeeper的理解&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper的理解&quot;&gt;&lt;/a&gt;Zookeeper的理解&lt;/h3&gt;&lt;p&gt;​    zookeeper是apache的一个项目，是一个
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>hexo + github搭建个人博客</title>
    <link href="http://yoursite.com/2019/06/30/hexo-github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>http://yoursite.com/2019/06/30/hexo-github搭建个人博客/</id>
    <published>2019-06-30T12:51:08.000Z</published>
    <updated>2019-06-30T13:30:43.059Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用hexo-github搭建个人博客"><a href="#使用hexo-github搭建个人博客" class="headerlink" title="使用hexo+github搭建个人博客"></a>使用hexo+github搭建个人博客</h1><p>使用github作为后台服务器，采用hexo进行博客的搭建，非常简单。大致有以下步骤</p><h4 id="1-首先本地要有安装有git，并且安装nodejs-并配置好环境变量"><a href="#1-首先本地要有安装有git，并且安装nodejs-并配置好环境变量" class="headerlink" title="1.首先本地要有安装有git，并且安装nodejs,并配置好环境变量"></a>1.首先本地要有安装有git，并且安装nodejs,并配置好环境变量</h4><h4 id="2-搞一个github账号"><a href="#2-搞一个github账号" class="headerlink" title="2.搞一个github账号"></a>2.搞一个github账号</h4><h4 id="3-在github上创建一个repository，格式为yourGitHubName-github-io"><a href="#3-在github上创建一个repository，格式为yourGitHubName-github-io" class="headerlink" title="3.在github上创建一个repository，格式为yourGitHubName.github.io"></a>3.在github上创建一个repository，格式为yourGitHubName.github.io</h4><h4 id="4-本地生成SSH，并绑定到你的github账号"><a href="#4-本地生成SSH，并绑定到你的github账号" class="headerlink" title="4.本地生成SSH，并绑定到你的github账号"></a>4.本地生成SSH，并绑定到你的github账号</h4><h4 id="5-将hexo部署到github"><a href="#5-将hexo部署到github" class="headerlink" title="5.将hexo部署到github"></a>5.将hexo部署到github</h4><h4 id="6-格式化hexo，发布文章"><a href="#6-格式化hexo，发布文章" class="headerlink" title="6.格式化hexo，发布文章"></a>6.格式化hexo，发布文章</h4><h4 id="7-查看。设置个人域名"><a href="#7-查看。设置个人域名" class="headerlink" title="7.查看。设置个人域名"></a>7.查看。设置个人域名</h4><p><img src="assets/skr.jpeg" alt="skr"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;使用hexo-github搭建个人博客&quot;&gt;&lt;a href=&quot;#使用hexo-github搭建个人博客&quot; class=&quot;headerlink&quot; title=&quot;使用hexo+github搭建个人博客&quot;&gt;&lt;/a&gt;使用hexo+github搭建个人博客&lt;/h1&gt;&lt;p&gt;使用
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2019/06/30/hello-world/"/>
    <id>http://yoursite.com/2019/06/30/hello-world/</id>
    <published>2019-06-30T07:26:57.832Z</published>
    <updated>2019-06-30T07:26:57.833Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
